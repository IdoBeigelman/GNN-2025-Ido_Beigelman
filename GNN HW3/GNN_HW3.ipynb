{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03SRW_GqbmZw"
      },
      "outputs": [],
      "source": [
        "! pip install \"numpy<2\" --force-reinstall\n",
        "! pip install torch==2.4 pandas scikit-learn pyvis\n",
        "! pip install dgl -f https://data.dgl.ai/wheels/torch-2.4/\n",
        "! pip install torchdata==0.6.1 --force-reinstall\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchdata.datapipes.iter import IterDataPipe\n",
        "\n",
        "import os\n",
        "os.environ['DGLBACKEND'] = 'pytorch'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import dgl\n",
        "import dgl.data as ddta\n",
        "import dgl.nn as dnn\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
        "\n",
        "import pyvis.network as pyv_n\n",
        "import itertools\n"
      ],
      "metadata": {
        "id": "UgbiOlcabpFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dgl.data.CoraGraphDataset()\n",
        "graph = dataset[0]"
      ],
      "metadata": {
        "id": "GEjPFY5ibuZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    dgl.random.seed(seed)\n",
        "\n",
        "    # If using CUDA\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.cuda.manual_seed_all(seed)  # if multi-GPU\n",
        "\n",
        "    # For deterministic behavior (optional but useful)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "Kr_em4JugvYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "\n",
        "def train_and_test(model,num_epochs = 20):\n",
        "    set_seed(42)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    best_val_acc = -1\n",
        "    all_features = graph.ndata[\"feat\"]\n",
        "    all_labels = graph.ndata[\"label\"]\n",
        "    train_mask = graph.ndata[\"train_mask\"]\n",
        "    val_mask = graph.ndata[\"val_mask\"]\n",
        "    test_mask = graph.ndata[\"test_mask\"]\n",
        "\n",
        "    for epoch_id in range(num_epochs):\n",
        "        probabilities = model(graph, all_features)\n",
        "        predictions = probabilities.argmax(1)\n",
        "\n",
        "        training_loss = F.cross_entropy(probabilities[train_mask], all_labels[train_mask])\n",
        "\n",
        "        train_acc = (predictions[train_mask] == all_labels[train_mask]).float().mean()\n",
        "        val_acc = (predictions[val_mask] == all_labels[val_mask]).float().mean()\n",
        "\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        training_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        print(\"Epoch {}, total loss: {:.3f}, train acc: {:.3f}, val acc: {:.3f} (best {:.3f})\".format(\n",
        "                    epoch_id, training_loss, train_acc, val_acc, best_val_acc))\n",
        "\n",
        "\n",
        "\n",
        "    test_probabilities = model(graph, all_features)[test_mask]\n",
        "    test_predictions = test_probabilities.argmax(1)\n",
        "\n",
        "    correct = (test_predictions == all_labels[test_mask]).float()\n",
        "    accuracy = correct.mean() * 100\n",
        "\n",
        "    print(\"Prediction accuracy on the test data is {:.1f}%\".format(accuracy.item()))\n",
        "\n"
      ],
      "metadata": {
        "id": "Ib2JmHAgbwzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = self.conv2(graph, vec_rep)\n",
        "        vec_rep = self.linear(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train_and_test(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1jDaFsnbx9L",
        "outputId": "7188b4ca-8757-47bd-dec2-222f8038282b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 1.962, train acc: 0.136, val acc: 0.166 (best 0.166)\n",
            "Epoch 1, total loss: 1.925, train acc: 0.200, val acc: 0.180 (best 0.180)\n",
            "Epoch 2, total loss: 1.886, train acc: 0.279, val acc: 0.198 (best 0.198)\n",
            "Epoch 3, total loss: 1.844, train acc: 0.529, val acc: 0.278 (best 0.278)\n",
            "Epoch 4, total loss: 1.795, train acc: 0.750, val acc: 0.396 (best 0.396)\n",
            "Epoch 5, total loss: 1.746, train acc: 0.793, val acc: 0.414 (best 0.414)\n",
            "Epoch 6, total loss: 1.684, train acc: 0.857, val acc: 0.410 (best 0.414)\n",
            "Epoch 7, total loss: 1.614, train acc: 0.864, val acc: 0.406 (best 0.414)\n",
            "Epoch 8, total loss: 1.537, train acc: 0.929, val acc: 0.398 (best 0.414)\n",
            "Epoch 9, total loss: 1.447, train acc: 0.914, val acc: 0.426 (best 0.426)\n",
            "Epoch 10, total loss: 1.365, train acc: 0.950, val acc: 0.482 (best 0.482)\n",
            "Epoch 11, total loss: 1.268, train acc: 0.950, val acc: 0.476 (best 0.482)\n",
            "Epoch 12, total loss: 1.186, train acc: 0.979, val acc: 0.548 (best 0.548)\n",
            "Epoch 13, total loss: 1.095, train acc: 0.971, val acc: 0.572 (best 0.572)\n",
            "Epoch 14, total loss: 0.975, train acc: 0.986, val acc: 0.596 (best 0.596)\n",
            "Epoch 15, total loss: 0.894, train acc: 0.986, val acc: 0.634 (best 0.634)\n",
            "Epoch 16, total loss: 0.773, train acc: 0.993, val acc: 0.648 (best 0.648)\n",
            "Epoch 17, total loss: 0.701, train acc: 0.986, val acc: 0.676 (best 0.676)\n",
            "Epoch 18, total loss: 0.609, train acc: 0.993, val acc: 0.674 (best 0.676)\n",
            "Epoch 19, total loss: 0.534, train acc: 0.993, val acc: 0.680 (best 0.680)\n",
            "Prediction accuracy on the test data is 71.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets check if adding more convolution improves the accuracy"
      ],
      "metadata": {
        "id": "POU-ZPnchrNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv3 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv4 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = self.conv2(graph, vec_rep)\n",
        "        vec_rep = self.conv3(graph, vec_rep)\n",
        "        vec_rep = self.conv4(graph, vec_rep)\n",
        "\n",
        "        vec_rep = self.linear(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train_and_test(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z0T1YmYhWDt",
        "outputId": "67d3050d-310f-433b-a6bd-3eb01d03e935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 2.064, train acc: 0.193, val acc: 0.074 (best 0.074)\n",
            "Epoch 1, total loss: 1.890, train acc: 0.229, val acc: 0.294 (best 0.294)\n",
            "Epoch 2, total loss: 1.786, train acc: 0.343, val acc: 0.248 (best 0.294)\n",
            "Epoch 3, total loss: 1.637, train acc: 0.471, val acc: 0.222 (best 0.294)\n",
            "Epoch 4, total loss: 1.484, train acc: 0.564, val acc: 0.346 (best 0.346)\n",
            "Epoch 5, total loss: 1.310, train acc: 0.643, val acc: 0.402 (best 0.402)\n",
            "Epoch 6, total loss: 1.145, train acc: 0.636, val acc: 0.424 (best 0.424)\n",
            "Epoch 7, total loss: 1.002, train acc: 0.707, val acc: 0.464 (best 0.464)\n",
            "Epoch 8, total loss: 0.838, train acc: 0.771, val acc: 0.448 (best 0.464)\n",
            "Epoch 9, total loss: 0.677, train acc: 0.807, val acc: 0.466 (best 0.466)\n",
            "Epoch 10, total loss: 0.567, train acc: 0.879, val acc: 0.468 (best 0.468)\n",
            "Epoch 11, total loss: 0.438, train acc: 0.929, val acc: 0.496 (best 0.496)\n",
            "Epoch 12, total loss: 0.325, train acc: 0.971, val acc: 0.536 (best 0.536)\n",
            "Epoch 13, total loss: 0.249, train acc: 0.979, val acc: 0.570 (best 0.570)\n",
            "Epoch 14, total loss: 0.191, train acc: 0.986, val acc: 0.574 (best 0.574)\n",
            "Epoch 15, total loss: 0.128, train acc: 0.993, val acc: 0.598 (best 0.598)\n",
            "Epoch 16, total loss: 0.092, train acc: 1.000, val acc: 0.602 (best 0.602)\n",
            "Epoch 17, total loss: 0.081, train acc: 0.979, val acc: 0.620 (best 0.620)\n",
            "Epoch 18, total loss: 0.047, train acc: 0.993, val acc: 0.606 (best 0.620)\n",
            "Epoch 19, total loss: 0.027, train acc: 1.000, val acc: 0.620 (best 0.620)\n",
            "Prediction accuracy on the test data is 64.1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding more convolutions leads to overfitting.Lets now check different aggreation types"
      ],
      "metadata": {
        "id": "mtYUVZI_h1YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"pool\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"pool\", feat_drop=0.1)\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = self.conv2(graph, vec_rep)\n",
        "        vec_rep = self.linear(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train_and_test(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIl9UPLUiB2z",
        "outputId": "554dc56b-9b63-4947-f2c5-dd42ec17a727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 1.974, train acc: 0.143, val acc: 0.122 (best 0.122)\n",
            "Epoch 1, total loss: 1.833, train acc: 0.329, val acc: 0.114 (best 0.122)\n",
            "Epoch 2, total loss: 1.614, train acc: 0.707, val acc: 0.410 (best 0.410)\n",
            "Epoch 3, total loss: 1.382, train acc: 0.571, val acc: 0.298 (best 0.410)\n",
            "Epoch 4, total loss: 1.037, train acc: 0.800, val acc: 0.576 (best 0.576)\n",
            "Epoch 5, total loss: 0.757, train acc: 0.936, val acc: 0.598 (best 0.598)\n",
            "Epoch 6, total loss: 0.523, train acc: 0.929, val acc: 0.544 (best 0.598)\n",
            "Epoch 7, total loss: 0.333, train acc: 0.979, val acc: 0.640 (best 0.640)\n",
            "Epoch 8, total loss: 0.195, train acc: 0.964, val acc: 0.664 (best 0.664)\n",
            "Epoch 9, total loss: 0.094, train acc: 0.993, val acc: 0.614 (best 0.664)\n",
            "Epoch 10, total loss: 0.072, train acc: 0.979, val acc: 0.666 (best 0.666)\n",
            "Epoch 11, total loss: 0.023, train acc: 1.000, val acc: 0.678 (best 0.678)\n",
            "Epoch 12, total loss: 0.024, train acc: 1.000, val acc: 0.660 (best 0.678)\n",
            "Epoch 13, total loss: 0.018, train acc: 0.993, val acc: 0.664 (best 0.678)\n",
            "Epoch 14, total loss: 0.004, train acc: 1.000, val acc: 0.682 (best 0.682)\n",
            "Epoch 15, total loss: 0.004, train acc: 1.000, val acc: 0.704 (best 0.704)\n",
            "Epoch 16, total loss: 0.001, train acc: 1.000, val acc: 0.680 (best 0.704)\n",
            "Epoch 17, total loss: 0.001, train acc: 1.000, val acc: 0.706 (best 0.706)\n",
            "Epoch 18, total loss: 0.001, train acc: 1.000, val acc: 0.678 (best 0.706)\n",
            "Epoch 19, total loss: 0.001, train acc: 1.000, val acc: 0.710 (best 0.710)\n",
            "Prediction accuracy on the test data is 70.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This does not seem to help. In order to prevent overfitting well add drop out"
      ],
      "metadata": {
        "id": "aPMkor-fiTGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = F.dropout(vec_rep, 0.3)\n",
        "        vec_rep = self.conv2(graph, vec_rep)\n",
        "        vec_rep = F.dropout(vec_rep, 0.3)\n",
        "        vec_rep = self.linear(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train_and_test(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaolZsdtiiUo",
        "outputId": "bfa0a3ac-7fdb-46e3-fa35-057d4e15f449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 1.962, train acc: 0.143, val acc: 0.152 (best 0.152)\n",
            "Epoch 1, total loss: 1.929, train acc: 0.186, val acc: 0.148 (best 0.152)\n",
            "Epoch 2, total loss: 1.899, train acc: 0.214, val acc: 0.184 (best 0.184)\n",
            "Epoch 3, total loss: 1.863, train acc: 0.307, val acc: 0.222 (best 0.222)\n",
            "Epoch 4, total loss: 1.837, train acc: 0.407, val acc: 0.256 (best 0.256)\n",
            "Epoch 5, total loss: 1.792, train acc: 0.464, val acc: 0.242 (best 0.256)\n",
            "Epoch 6, total loss: 1.749, train acc: 0.493, val acc: 0.274 (best 0.274)\n",
            "Epoch 7, total loss: 1.694, train acc: 0.607, val acc: 0.302 (best 0.302)\n",
            "Epoch 8, total loss: 1.648, train acc: 0.600, val acc: 0.316 (best 0.316)\n",
            "Epoch 9, total loss: 1.592, train acc: 0.714, val acc: 0.302 (best 0.316)\n",
            "Epoch 10, total loss: 1.496, train acc: 0.664, val acc: 0.330 (best 0.330)\n",
            "Epoch 11, total loss: 1.409, train acc: 0.736, val acc: 0.384 (best 0.384)\n",
            "Epoch 12, total loss: 1.359, train acc: 0.771, val acc: 0.390 (best 0.390)\n",
            "Epoch 13, total loss: 1.333, train acc: 0.764, val acc: 0.414 (best 0.414)\n",
            "Epoch 14, total loss: 1.192, train acc: 0.814, val acc: 0.478 (best 0.478)\n",
            "Epoch 15, total loss: 1.136, train acc: 0.843, val acc: 0.500 (best 0.500)\n",
            "Epoch 16, total loss: 1.041, train acc: 0.914, val acc: 0.560 (best 0.560)\n",
            "Epoch 17, total loss: 0.971, train acc: 0.886, val acc: 0.556 (best 0.560)\n",
            "Epoch 18, total loss: 0.878, train acc: 0.871, val acc: 0.608 (best 0.608)\n",
            "Epoch 19, total loss: 0.791, train acc: 0.921, val acc: 0.624 (best 0.624)\n",
            "Prediction accuracy on the test data is 61.1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This does not help. Lets try reducing the hidden dimension"
      ],
      "metadata": {
        "id": "kkx8Z0SQix26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = self.conv2(graph, vec_rep)\n",
        "        vec_rep = self.linear(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 8, dataset.num_classes)\n",
        "train_and_test(model,num_epochs=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x08mXghHi3sY",
        "outputId": "a631d488-db3a-47e2-c9bd-64d97d3c92ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 1.969, train acc: 0.143, val acc: 0.122 (best 0.122)\n",
            "Epoch 1, total loss: 1.940, train acc: 0.143, val acc: 0.122 (best 0.122)\n",
            "Epoch 2, total loss: 1.908, train acc: 0.143, val acc: 0.122 (best 0.122)\n",
            "Epoch 3, total loss: 1.875, train acc: 0.143, val acc: 0.122 (best 0.122)\n",
            "Epoch 4, total loss: 1.838, train acc: 0.179, val acc: 0.122 (best 0.122)\n",
            "Epoch 5, total loss: 1.803, train acc: 0.350, val acc: 0.134 (best 0.134)\n",
            "Epoch 6, total loss: 1.763, train acc: 0.529, val acc: 0.186 (best 0.186)\n",
            "Epoch 7, total loss: 1.729, train acc: 0.686, val acc: 0.296 (best 0.296)\n",
            "Epoch 8, total loss: 1.679, train acc: 0.793, val acc: 0.404 (best 0.404)\n",
            "Epoch 9, total loss: 1.620, train acc: 0.836, val acc: 0.456 (best 0.456)\n",
            "Epoch 10, total loss: 1.572, train acc: 0.843, val acc: 0.508 (best 0.508)\n",
            "Epoch 11, total loss: 1.507, train acc: 0.807, val acc: 0.500 (best 0.508)\n",
            "Epoch 12, total loss: 1.458, train acc: 0.793, val acc: 0.514 (best 0.514)\n",
            "Epoch 13, total loss: 1.390, train acc: 0.800, val acc: 0.512 (best 0.514)\n",
            "Epoch 14, total loss: 1.328, train acc: 0.807, val acc: 0.516 (best 0.516)\n",
            "Epoch 15, total loss: 1.273, train acc: 0.829, val acc: 0.544 (best 0.544)\n",
            "Epoch 16, total loss: 1.202, train acc: 0.836, val acc: 0.580 (best 0.580)\n",
            "Epoch 17, total loss: 1.150, train acc: 0.836, val acc: 0.560 (best 0.580)\n",
            "Epoch 18, total loss: 1.091, train acc: 0.857, val acc: 0.584 (best 0.584)\n",
            "Epoch 19, total loss: 1.031, train acc: 0.864, val acc: 0.620 (best 0.620)\n",
            "Epoch 20, total loss: 0.945, train acc: 0.893, val acc: 0.622 (best 0.622)\n",
            "Epoch 21, total loss: 0.890, train acc: 0.900, val acc: 0.638 (best 0.638)\n",
            "Epoch 22, total loss: 0.817, train acc: 0.907, val acc: 0.658 (best 0.658)\n",
            "Epoch 23, total loss: 0.755, train acc: 0.921, val acc: 0.690 (best 0.690)\n",
            "Epoch 24, total loss: 0.698, train acc: 0.914, val acc: 0.684 (best 0.690)\n",
            "Epoch 25, total loss: 0.631, train acc: 0.936, val acc: 0.690 (best 0.690)\n",
            "Epoch 26, total loss: 0.603, train acc: 0.929, val acc: 0.670 (best 0.690)\n",
            "Epoch 27, total loss: 0.532, train acc: 0.950, val acc: 0.698 (best 0.698)\n",
            "Epoch 28, total loss: 0.494, train acc: 0.964, val acc: 0.690 (best 0.698)\n",
            "Epoch 29, total loss: 0.445, train acc: 0.971, val acc: 0.694 (best 0.698)\n",
            "Prediction accuracy on the test data is 68.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Ill try reducing the convolutions and adding another linear layer"
      ],
      "metadata": {
        "id": "kEbwZJJ7jhCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.linear1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = self.linear1(vec_rep)\n",
        "        vec_rep = F.relu(vec_rep)\n",
        "        vec_rep = self.linear2(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train_and_test(model,num_epochs = 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WOCB_Z6jlvz",
        "outputId": "3a53c8ff-4b31-4b04-f30a-c8d8682dec45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 1.960, train acc: 0.129, val acc: 0.276 (best 0.276)\n",
            "Epoch 1, total loss: 1.950, train acc: 0.200, val acc: 0.322 (best 0.322)\n",
            "Epoch 2, total loss: 1.939, train acc: 0.236, val acc: 0.330 (best 0.330)\n",
            "Epoch 3, total loss: 1.927, train acc: 0.279, val acc: 0.324 (best 0.330)\n",
            "Epoch 4, total loss: 1.913, train acc: 0.336, val acc: 0.322 (best 0.330)\n",
            "Epoch 5, total loss: 1.897, train acc: 0.400, val acc: 0.332 (best 0.332)\n",
            "Epoch 6, total loss: 1.879, train acc: 0.436, val acc: 0.354 (best 0.354)\n",
            "Epoch 7, total loss: 1.856, train acc: 0.714, val acc: 0.320 (best 0.354)\n",
            "Epoch 8, total loss: 1.832, train acc: 0.750, val acc: 0.156 (best 0.354)\n",
            "Epoch 9, total loss: 1.803, train acc: 0.679, val acc: 0.144 (best 0.354)\n",
            "Epoch 10, total loss: 1.772, train acc: 0.664, val acc: 0.174 (best 0.354)\n",
            "Epoch 11, total loss: 1.737, train acc: 0.686, val acc: 0.184 (best 0.354)\n",
            "Epoch 12, total loss: 1.698, train acc: 0.693, val acc: 0.196 (best 0.354)\n",
            "Epoch 13, total loss: 1.655, train acc: 0.707, val acc: 0.222 (best 0.354)\n",
            "Epoch 14, total loss: 1.611, train acc: 0.729, val acc: 0.240 (best 0.354)\n",
            "Epoch 15, total loss: 1.558, train acc: 0.714, val acc: 0.244 (best 0.354)\n",
            "Epoch 16, total loss: 1.503, train acc: 0.786, val acc: 0.258 (best 0.354)\n",
            "Epoch 17, total loss: 1.451, train acc: 0.814, val acc: 0.270 (best 0.354)\n",
            "Epoch 18, total loss: 1.383, train acc: 0.821, val acc: 0.290 (best 0.354)\n",
            "Epoch 19, total loss: 1.325, train acc: 0.843, val acc: 0.314 (best 0.354)\n",
            "Epoch 20, total loss: 1.258, train acc: 0.900, val acc: 0.322 (best 0.354)\n",
            "Epoch 21, total loss: 1.189, train acc: 0.929, val acc: 0.354 (best 0.354)\n",
            "Epoch 22, total loss: 1.119, train acc: 0.957, val acc: 0.370 (best 0.370)\n",
            "Epoch 23, total loss: 1.044, train acc: 0.986, val acc: 0.388 (best 0.388)\n",
            "Epoch 24, total loss: 0.964, train acc: 0.993, val acc: 0.432 (best 0.432)\n",
            "Epoch 25, total loss: 0.886, train acc: 1.000, val acc: 0.464 (best 0.464)\n",
            "Epoch 26, total loss: 0.807, train acc: 1.000, val acc: 0.484 (best 0.484)\n",
            "Epoch 27, total loss: 0.721, train acc: 1.000, val acc: 0.534 (best 0.534)\n",
            "Epoch 28, total loss: 0.652, train acc: 1.000, val acc: 0.502 (best 0.534)\n",
            "Epoch 29, total loss: 0.578, train acc: 1.000, val acc: 0.524 (best 0.534)\n",
            "Prediction accuracy on the test data is 52.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the end after testing different sets of hyperparameters the best resulting set was using a hidden layer of 16 with 2 different convolution layers and a linear layer at the end. The convolutions were done with a mean aggregator. For this dataset simpler and smaller models performed best"
      ],
      "metadata": {
        "id": "BBHazF5oangm"
      }
    }
  ]
}