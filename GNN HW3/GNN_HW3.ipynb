{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5653ca6ef95c4afc8314b82699e64cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04d664b100e04a839095400f642d3582",
              "IPY_MODEL_274abed69d0443f9b04699c51d803026",
              "IPY_MODEL_e61a1d2ad5944218aaf70e88b2b6e423"
            ],
            "layout": "IPY_MODEL_26fd7b72807743e397cc10733dc6d6c4"
          }
        },
        "04d664b100e04a839095400f642d3582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96d35ca288fe44d5a0a89b3aa67e8982",
            "placeholder": "​",
            "style": "IPY_MODEL_01113f4625e64a6b8c01145270f6be2f",
            "value": "/root/.dgl/cora_v2.zip: 100%"
          }
        },
        "274abed69d0443f9b04699c51d803026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfca435210a04b4fbf48872f157d8caa",
            "max": 132173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6081cd314a0b4ab2990323793a994896",
            "value": 132173
          }
        },
        "e61a1d2ad5944218aaf70e88b2b6e423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adf607a91f454b459346703e3605561c",
            "placeholder": "​",
            "style": "IPY_MODEL_6d8b88711ccd497ea8ce9911ffacbbb1",
            "value": " 132k/132k [00:00&lt;00:00, 4.24MB/s]"
          }
        },
        "26fd7b72807743e397cc10733dc6d6c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96d35ca288fe44d5a0a89b3aa67e8982": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01113f4625e64a6b8c01145270f6be2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfca435210a04b4fbf48872f157d8caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6081cd314a0b4ab2990323793a994896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adf607a91f454b459346703e3605561c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8b88711ccd497ea8ce9911ffacbbb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "03SRW_GqbmZw",
        "outputId": "28164075-6730-4f0f-ceae-3fe5f152d408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Collecting torch==2.4\n",
            "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4) (12.5.82)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pyvis) (4.0.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n",
            "Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, pyvis\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jedi-0.19.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 pyvis-0.3.2 torch-2.4.0 triton-3.0.0\n",
            "Looking in links: https://data.dgl.ai/wheels/torch-2.4/\n",
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (553 bytes)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.14.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl) (4.67.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (5.9.5)\n",
            "Collecting torchdata>=0.5.0 (from dgl)\n",
            "  Downloading torchdata-0.11.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2025.1.31)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata>=0.5.0->dgl) (2.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Downloading dgl-2.1.0-cp311-cp311-manylinux1_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchdata, dgl\n",
            "Successfully installed dgl-2.1.0 torchdata-0.11.0\n",
            "Collecting torchdata==0.6.1\n",
            "  Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting urllib3>=1.25 (from torchdata==0.6.1)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting requests (from torchdata==0.6.1)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting torch==2.0.1 (from torchdata==0.6.1)\n",
            "  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting filelock (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting setuptools (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading cmake-4.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->torchdata==0.6.1)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchdata==0.6.1)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchdata==0.6.1)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.0.1->torchdata==0.6.1)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmake-4.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, lit, wheel, urllib3, typing-extensions, sympy, setuptools, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, networkx, MarkupSafe, idna, filelock, cmake, charset-normalizer, certifi, requests, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jinja2, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.1\n",
            "    Uninstalling typing_extensions-4.13.1:\n",
            "      Successfully uninstalled typing_extensions-4.13.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: cmake\n",
            "    Found existing installation: cmake 3.31.6\n",
            "    Uninstalling cmake-3.31.6:\n",
            "      Successfully uninstalled cmake-3.31.6\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.0.0\n",
            "    Uninstalling triton-3.0.0:\n",
            "      Successfully uninstalled triton-3.0.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0\n",
            "    Uninstalling torch-2.4.0:\n",
            "      Successfully uninstalled torch-2.4.0\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.11.0\n",
            "    Uninstalling torchdata-0.11.0:\n",
            "      Successfully uninstalled torchdata-0.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 certifi-2025.1.31 charset-normalizer-3.4.1 cmake-4.0.0 filelock-3.18.0 idna-3.10 jinja2-3.1.6 lit-18.1.8 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 requests-2.32.3 setuptools-78.1.0 sympy-1.13.3 torch-2.0.1 torchdata-0.6.1 triton-2.0.0 typing-extensions-4.13.2 urllib3-2.4.0 wheel-0.45.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi"
                ]
              },
              "id": "0bbe6e1e73a74888b7b23abd467094fb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install \"numpy<2\" --force-reinstall\n",
        "! pip install torch==2.4 pandas scikit-learn pyvis\n",
        "! pip install dgl -f https://data.dgl.ai/wheels/torch-2.4/\n",
        "! pip install torchdata==0.6.1 --force-reinstall\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchdata.datapipes.iter import IterDataPipe\n",
        "\n",
        "import os\n",
        "os.environ['DGLBACKEND'] = 'pytorch'\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import dgl\n",
        "import dgl.data as ddta\n",
        "import dgl.nn as dnn\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
        "\n",
        "import pyvis.network as pyv_n\n",
        "import itertools\n"
      ],
      "metadata": {
        "id": "UgbiOlcabpFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dgl.data.CoraGraphDataset()\n",
        "graph = dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245,
          "referenced_widgets": [
            "5653ca6ef95c4afc8314b82699e64cdb",
            "04d664b100e04a839095400f642d3582",
            "274abed69d0443f9b04699c51d803026",
            "e61a1d2ad5944218aaf70e88b2b6e423",
            "26fd7b72807743e397cc10733dc6d6c4",
            "96d35ca288fe44d5a0a89b3aa67e8982",
            "01113f4625e64a6b8c01145270f6be2f",
            "bfca435210a04b4fbf48872f157d8caa",
            "6081cd314a0b4ab2990323793a994896",
            "adf607a91f454b459346703e3605561c",
            "6d8b88711ccd497ea8ce9911ffacbbb1"
          ]
        },
        "id": "GEjPFY5ibuZj",
        "outputId": "7c865a53-0c9a-4452-8615-3431f772fc3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/root/.dgl/cora_v2.zip:   0%|          | 0.00/132k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5653ca6ef95c4afc8314b82699e64cdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to /root/.dgl/cora_v2_d697a464\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    dgl.random.seed(seed)\n",
        "\n",
        "    # If using CUDA\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.cuda.manual_seed_all(seed)  # if multi-GPU\n",
        "\n",
        "    # For deterministic behavior (optional but useful)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "Kr_em4JugvYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "\n",
        "def train_and_test(model,num_epochs = 20):\n",
        "    set_seed(42)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    best_val_acc = -1\n",
        "    all_features = graph.ndata[\"feat\"]\n",
        "    all_labels = graph.ndata[\"label\"]\n",
        "    train_mask = graph.ndata[\"train_mask\"]\n",
        "    val_mask = graph.ndata[\"val_mask\"]\n",
        "    test_mask = graph.ndata[\"test_mask\"]\n",
        "\n",
        "    for epoch_id in range(num_epochs):\n",
        "        probabilities = model(graph, all_features)\n",
        "        predictions = probabilities.argmax(1)\n",
        "\n",
        "        training_loss = F.cross_entropy(probabilities[train_mask], all_labels[train_mask])\n",
        "\n",
        "        train_acc = (predictions[train_mask] == all_labels[train_mask]).float().mean()\n",
        "        val_acc = (predictions[val_mask] == all_labels[val_mask]).float().mean()\n",
        "\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        training_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        print(\"Epoch {}, total loss: {:.3f}, train acc: {:.3f}, val acc: {:.3f} (best {:.3f})\".format(\n",
        "                    epoch_id, training_loss, train_acc, val_acc, best_val_acc))\n",
        "\n",
        "\n",
        "\n",
        "    test_probabilities = model(graph, all_features)[test_mask]\n",
        "    test_predictions = test_probabilities.argmax(1)\n",
        "\n",
        "    correct = (test_predictions == all_labels[test_mask]).float()\n",
        "    accuracy = correct.mean() * 100\n",
        "\n",
        "    print(\"Prediction accuracy on the test data is {:.1f}%\".format(accuracy.item()))\n",
        "\n"
      ],
      "metadata": {
        "id": "Ib2JmHAgbwzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = self.conv2(graph, vec_rep)\n",
        "        vec_rep = self.linear(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train_and_test(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1jDaFsnbx9L",
        "outputId": "7188b4ca-8757-47bd-dec2-222f8038282b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 1.962, train acc: 0.136, val acc: 0.166 (best 0.166)\n",
            "Epoch 1, total loss: 1.925, train acc: 0.200, val acc: 0.180 (best 0.180)\n",
            "Epoch 2, total loss: 1.886, train acc: 0.279, val acc: 0.198 (best 0.198)\n",
            "Epoch 3, total loss: 1.844, train acc: 0.529, val acc: 0.278 (best 0.278)\n",
            "Epoch 4, total loss: 1.795, train acc: 0.750, val acc: 0.396 (best 0.396)\n",
            "Epoch 5, total loss: 1.746, train acc: 0.793, val acc: 0.414 (best 0.414)\n",
            "Epoch 6, total loss: 1.684, train acc: 0.857, val acc: 0.410 (best 0.414)\n",
            "Epoch 7, total loss: 1.614, train acc: 0.864, val acc: 0.406 (best 0.414)\n",
            "Epoch 8, total loss: 1.537, train acc: 0.929, val acc: 0.398 (best 0.414)\n",
            "Epoch 9, total loss: 1.447, train acc: 0.914, val acc: 0.426 (best 0.426)\n",
            "Epoch 10, total loss: 1.365, train acc: 0.950, val acc: 0.482 (best 0.482)\n",
            "Epoch 11, total loss: 1.268, train acc: 0.950, val acc: 0.476 (best 0.482)\n",
            "Epoch 12, total loss: 1.186, train acc: 0.979, val acc: 0.548 (best 0.548)\n",
            "Epoch 13, total loss: 1.095, train acc: 0.971, val acc: 0.572 (best 0.572)\n",
            "Epoch 14, total loss: 0.975, train acc: 0.986, val acc: 0.596 (best 0.596)\n",
            "Epoch 15, total loss: 0.894, train acc: 0.986, val acc: 0.634 (best 0.634)\n",
            "Epoch 16, total loss: 0.773, train acc: 0.993, val acc: 0.648 (best 0.648)\n",
            "Epoch 17, total loss: 0.701, train acc: 0.986, val acc: 0.676 (best 0.676)\n",
            "Epoch 18, total loss: 0.609, train acc: 0.993, val acc: 0.674 (best 0.676)\n",
            "Epoch 19, total loss: 0.534, train acc: 0.993, val acc: 0.680 (best 0.680)\n",
            "Prediction accuracy on the test data is 71.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets check if adding more convolution improves the accuracy"
      ],
      "metadata": {
        "id": "POU-ZPnchrNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv3 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv4 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = self.conv2(graph, vec_rep)\n",
        "        vec_rep = self.conv3(graph, vec_rep)\n",
        "        vec_rep = self.conv4(graph, vec_rep)\n",
        "\n",
        "        vec_rep = self.linear(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train_and_test(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z0T1YmYhWDt",
        "outputId": "67d3050d-310f-433b-a6bd-3eb01d03e935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 2.064, train acc: 0.193, val acc: 0.074 (best 0.074)\n",
            "Epoch 1, total loss: 1.890, train acc: 0.229, val acc: 0.294 (best 0.294)\n",
            "Epoch 2, total loss: 1.786, train acc: 0.343, val acc: 0.248 (best 0.294)\n",
            "Epoch 3, total loss: 1.637, train acc: 0.471, val acc: 0.222 (best 0.294)\n",
            "Epoch 4, total loss: 1.484, train acc: 0.564, val acc: 0.346 (best 0.346)\n",
            "Epoch 5, total loss: 1.310, train acc: 0.643, val acc: 0.402 (best 0.402)\n",
            "Epoch 6, total loss: 1.145, train acc: 0.636, val acc: 0.424 (best 0.424)\n",
            "Epoch 7, total loss: 1.002, train acc: 0.707, val acc: 0.464 (best 0.464)\n",
            "Epoch 8, total loss: 0.838, train acc: 0.771, val acc: 0.448 (best 0.464)\n",
            "Epoch 9, total loss: 0.677, train acc: 0.807, val acc: 0.466 (best 0.466)\n",
            "Epoch 10, total loss: 0.567, train acc: 0.879, val acc: 0.468 (best 0.468)\n",
            "Epoch 11, total loss: 0.438, train acc: 0.929, val acc: 0.496 (best 0.496)\n",
            "Epoch 12, total loss: 0.325, train acc: 0.971, val acc: 0.536 (best 0.536)\n",
            "Epoch 13, total loss: 0.249, train acc: 0.979, val acc: 0.570 (best 0.570)\n",
            "Epoch 14, total loss: 0.191, train acc: 0.986, val acc: 0.574 (best 0.574)\n",
            "Epoch 15, total loss: 0.128, train acc: 0.993, val acc: 0.598 (best 0.598)\n",
            "Epoch 16, total loss: 0.092, train acc: 1.000, val acc: 0.602 (best 0.602)\n",
            "Epoch 17, total loss: 0.081, train acc: 0.979, val acc: 0.620 (best 0.620)\n",
            "Epoch 18, total loss: 0.047, train acc: 0.993, val acc: 0.606 (best 0.620)\n",
            "Epoch 19, total loss: 0.027, train acc: 1.000, val acc: 0.620 (best 0.620)\n",
            "Prediction accuracy on the test data is 64.1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding more convolutions leads to overfitting.Lets now check different aggreation types"
      ],
      "metadata": {
        "id": "mtYUVZI_h1YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"pool\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"pool\", feat_drop=0.1)\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = self.conv2(graph, vec_rep)\n",
        "        vec_rep = self.linear(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train_and_test(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIl9UPLUiB2z",
        "outputId": "554dc56b-9b63-4947-f2c5-dd42ec17a727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 1.974, train acc: 0.143, val acc: 0.122 (best 0.122)\n",
            "Epoch 1, total loss: 1.833, train acc: 0.329, val acc: 0.114 (best 0.122)\n",
            "Epoch 2, total loss: 1.614, train acc: 0.707, val acc: 0.410 (best 0.410)\n",
            "Epoch 3, total loss: 1.382, train acc: 0.571, val acc: 0.298 (best 0.410)\n",
            "Epoch 4, total loss: 1.037, train acc: 0.800, val acc: 0.576 (best 0.576)\n",
            "Epoch 5, total loss: 0.757, train acc: 0.936, val acc: 0.598 (best 0.598)\n",
            "Epoch 6, total loss: 0.523, train acc: 0.929, val acc: 0.544 (best 0.598)\n",
            "Epoch 7, total loss: 0.333, train acc: 0.979, val acc: 0.640 (best 0.640)\n",
            "Epoch 8, total loss: 0.195, train acc: 0.964, val acc: 0.664 (best 0.664)\n",
            "Epoch 9, total loss: 0.094, train acc: 0.993, val acc: 0.614 (best 0.664)\n",
            "Epoch 10, total loss: 0.072, train acc: 0.979, val acc: 0.666 (best 0.666)\n",
            "Epoch 11, total loss: 0.023, train acc: 1.000, val acc: 0.678 (best 0.678)\n",
            "Epoch 12, total loss: 0.024, train acc: 1.000, val acc: 0.660 (best 0.678)\n",
            "Epoch 13, total loss: 0.018, train acc: 0.993, val acc: 0.664 (best 0.678)\n",
            "Epoch 14, total loss: 0.004, train acc: 1.000, val acc: 0.682 (best 0.682)\n",
            "Epoch 15, total loss: 0.004, train acc: 1.000, val acc: 0.704 (best 0.704)\n",
            "Epoch 16, total loss: 0.001, train acc: 1.000, val acc: 0.680 (best 0.704)\n",
            "Epoch 17, total loss: 0.001, train acc: 1.000, val acc: 0.706 (best 0.706)\n",
            "Epoch 18, total loss: 0.001, train acc: 1.000, val acc: 0.678 (best 0.706)\n",
            "Epoch 19, total loss: 0.001, train acc: 1.000, val acc: 0.710 (best 0.710)\n",
            "Prediction accuracy on the test data is 70.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This does not seem to help. In order to prevent overfitting well add drop out"
      ],
      "metadata": {
        "id": "aPMkor-fiTGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = F.dropout(vec_rep, 0.3)\n",
        "        vec_rep = self.conv2(graph, vec_rep)\n",
        "        vec_rep = F.dropout(vec_rep, 0.3)\n",
        "        vec_rep = self.linear(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train_and_test(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaolZsdtiiUo",
        "outputId": "bfa0a3ac-7fdb-46e3-fa35-057d4e15f449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 1.962, train acc: 0.143, val acc: 0.152 (best 0.152)\n",
            "Epoch 1, total loss: 1.929, train acc: 0.186, val acc: 0.148 (best 0.152)\n",
            "Epoch 2, total loss: 1.899, train acc: 0.214, val acc: 0.184 (best 0.184)\n",
            "Epoch 3, total loss: 1.863, train acc: 0.307, val acc: 0.222 (best 0.222)\n",
            "Epoch 4, total loss: 1.837, train acc: 0.407, val acc: 0.256 (best 0.256)\n",
            "Epoch 5, total loss: 1.792, train acc: 0.464, val acc: 0.242 (best 0.256)\n",
            "Epoch 6, total loss: 1.749, train acc: 0.493, val acc: 0.274 (best 0.274)\n",
            "Epoch 7, total loss: 1.694, train acc: 0.607, val acc: 0.302 (best 0.302)\n",
            "Epoch 8, total loss: 1.648, train acc: 0.600, val acc: 0.316 (best 0.316)\n",
            "Epoch 9, total loss: 1.592, train acc: 0.714, val acc: 0.302 (best 0.316)\n",
            "Epoch 10, total loss: 1.496, train acc: 0.664, val acc: 0.330 (best 0.330)\n",
            "Epoch 11, total loss: 1.409, train acc: 0.736, val acc: 0.384 (best 0.384)\n",
            "Epoch 12, total loss: 1.359, train acc: 0.771, val acc: 0.390 (best 0.390)\n",
            "Epoch 13, total loss: 1.333, train acc: 0.764, val acc: 0.414 (best 0.414)\n",
            "Epoch 14, total loss: 1.192, train acc: 0.814, val acc: 0.478 (best 0.478)\n",
            "Epoch 15, total loss: 1.136, train acc: 0.843, val acc: 0.500 (best 0.500)\n",
            "Epoch 16, total loss: 1.041, train acc: 0.914, val acc: 0.560 (best 0.560)\n",
            "Epoch 17, total loss: 0.971, train acc: 0.886, val acc: 0.556 (best 0.560)\n",
            "Epoch 18, total loss: 0.878, train acc: 0.871, val acc: 0.608 (best 0.608)\n",
            "Epoch 19, total loss: 0.791, train acc: 0.921, val acc: 0.624 (best 0.624)\n",
            "Prediction accuracy on the test data is 61.1%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This does not help. Lets try reducing the hidden dimension"
      ],
      "metadata": {
        "id": "kkx8Z0SQix26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = self.conv2(graph, vec_rep)\n",
        "        vec_rep = self.linear(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 8, dataset.num_classes)\n",
        "train_and_test(model,num_epochs=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x08mXghHi3sY",
        "outputId": "a631d488-db3a-47e2-c9bd-64d97d3c92ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 1.969, train acc: 0.143, val acc: 0.122 (best 0.122)\n",
            "Epoch 1, total loss: 1.940, train acc: 0.143, val acc: 0.122 (best 0.122)\n",
            "Epoch 2, total loss: 1.908, train acc: 0.143, val acc: 0.122 (best 0.122)\n",
            "Epoch 3, total loss: 1.875, train acc: 0.143, val acc: 0.122 (best 0.122)\n",
            "Epoch 4, total loss: 1.838, train acc: 0.179, val acc: 0.122 (best 0.122)\n",
            "Epoch 5, total loss: 1.803, train acc: 0.350, val acc: 0.134 (best 0.134)\n",
            "Epoch 6, total loss: 1.763, train acc: 0.529, val acc: 0.186 (best 0.186)\n",
            "Epoch 7, total loss: 1.729, train acc: 0.686, val acc: 0.296 (best 0.296)\n",
            "Epoch 8, total loss: 1.679, train acc: 0.793, val acc: 0.404 (best 0.404)\n",
            "Epoch 9, total loss: 1.620, train acc: 0.836, val acc: 0.456 (best 0.456)\n",
            "Epoch 10, total loss: 1.572, train acc: 0.843, val acc: 0.508 (best 0.508)\n",
            "Epoch 11, total loss: 1.507, train acc: 0.807, val acc: 0.500 (best 0.508)\n",
            "Epoch 12, total loss: 1.458, train acc: 0.793, val acc: 0.514 (best 0.514)\n",
            "Epoch 13, total loss: 1.390, train acc: 0.800, val acc: 0.512 (best 0.514)\n",
            "Epoch 14, total loss: 1.328, train acc: 0.807, val acc: 0.516 (best 0.516)\n",
            "Epoch 15, total loss: 1.273, train acc: 0.829, val acc: 0.544 (best 0.544)\n",
            "Epoch 16, total loss: 1.202, train acc: 0.836, val acc: 0.580 (best 0.580)\n",
            "Epoch 17, total loss: 1.150, train acc: 0.836, val acc: 0.560 (best 0.580)\n",
            "Epoch 18, total loss: 1.091, train acc: 0.857, val acc: 0.584 (best 0.584)\n",
            "Epoch 19, total loss: 1.031, train acc: 0.864, val acc: 0.620 (best 0.620)\n",
            "Epoch 20, total loss: 0.945, train acc: 0.893, val acc: 0.622 (best 0.622)\n",
            "Epoch 21, total loss: 0.890, train acc: 0.900, val acc: 0.638 (best 0.638)\n",
            "Epoch 22, total loss: 0.817, train acc: 0.907, val acc: 0.658 (best 0.658)\n",
            "Epoch 23, total loss: 0.755, train acc: 0.921, val acc: 0.690 (best 0.690)\n",
            "Epoch 24, total loss: 0.698, train acc: 0.914, val acc: 0.684 (best 0.690)\n",
            "Epoch 25, total loss: 0.631, train acc: 0.936, val acc: 0.690 (best 0.690)\n",
            "Epoch 26, total loss: 0.603, train acc: 0.929, val acc: 0.670 (best 0.690)\n",
            "Epoch 27, total loss: 0.532, train acc: 0.950, val acc: 0.698 (best 0.698)\n",
            "Epoch 28, total loss: 0.494, train acc: 0.964, val acc: 0.690 (best 0.698)\n",
            "Epoch 29, total loss: 0.445, train acc: 0.971, val acc: 0.694 (best 0.698)\n",
            "Prediction accuracy on the test data is 68.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Ill try reducing the convolutions and adding another linear layer"
      ],
      "metadata": {
        "id": "kEbwZJJ7jhCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_classes):\n",
        "        super(MyGraphSAGE, self).__init__()\n",
        "        self.conv1 = dnn.SAGEConv(in_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.conv2 = dnn.SAGEConv(hidden_dim, hidden_dim, aggregator_type=\"mean\", feat_drop=0.1)\n",
        "        self.linear1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, graph, node_features):\n",
        "        vec_rep = self.conv1(graph, node_features)\n",
        "        vec_rep = self.linear1(vec_rep)\n",
        "        vec_rep = F.relu(vec_rep)\n",
        "        vec_rep = self.linear2(vec_rep)\n",
        "        return vec_rep\n",
        "\n",
        "set_seed(42)\n",
        "model = MyGraphSAGE(graph.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\n",
        "train_and_test(model,num_epochs = 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WOCB_Z6jlvz",
        "outputId": "3a53c8ff-4b31-4b04-f30a-c8d8682dec45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, total loss: 1.960, train acc: 0.129, val acc: 0.276 (best 0.276)\n",
            "Epoch 1, total loss: 1.950, train acc: 0.200, val acc: 0.322 (best 0.322)\n",
            "Epoch 2, total loss: 1.939, train acc: 0.236, val acc: 0.330 (best 0.330)\n",
            "Epoch 3, total loss: 1.927, train acc: 0.279, val acc: 0.324 (best 0.330)\n",
            "Epoch 4, total loss: 1.913, train acc: 0.336, val acc: 0.322 (best 0.330)\n",
            "Epoch 5, total loss: 1.897, train acc: 0.400, val acc: 0.332 (best 0.332)\n",
            "Epoch 6, total loss: 1.879, train acc: 0.436, val acc: 0.354 (best 0.354)\n",
            "Epoch 7, total loss: 1.856, train acc: 0.714, val acc: 0.320 (best 0.354)\n",
            "Epoch 8, total loss: 1.832, train acc: 0.750, val acc: 0.156 (best 0.354)\n",
            "Epoch 9, total loss: 1.803, train acc: 0.679, val acc: 0.144 (best 0.354)\n",
            "Epoch 10, total loss: 1.772, train acc: 0.664, val acc: 0.174 (best 0.354)\n",
            "Epoch 11, total loss: 1.737, train acc: 0.686, val acc: 0.184 (best 0.354)\n",
            "Epoch 12, total loss: 1.698, train acc: 0.693, val acc: 0.196 (best 0.354)\n",
            "Epoch 13, total loss: 1.655, train acc: 0.707, val acc: 0.222 (best 0.354)\n",
            "Epoch 14, total loss: 1.611, train acc: 0.729, val acc: 0.240 (best 0.354)\n",
            "Epoch 15, total loss: 1.558, train acc: 0.714, val acc: 0.244 (best 0.354)\n",
            "Epoch 16, total loss: 1.503, train acc: 0.786, val acc: 0.258 (best 0.354)\n",
            "Epoch 17, total loss: 1.451, train acc: 0.814, val acc: 0.270 (best 0.354)\n",
            "Epoch 18, total loss: 1.383, train acc: 0.821, val acc: 0.290 (best 0.354)\n",
            "Epoch 19, total loss: 1.325, train acc: 0.843, val acc: 0.314 (best 0.354)\n",
            "Epoch 20, total loss: 1.258, train acc: 0.900, val acc: 0.322 (best 0.354)\n",
            "Epoch 21, total loss: 1.189, train acc: 0.929, val acc: 0.354 (best 0.354)\n",
            "Epoch 22, total loss: 1.119, train acc: 0.957, val acc: 0.370 (best 0.370)\n",
            "Epoch 23, total loss: 1.044, train acc: 0.986, val acc: 0.388 (best 0.388)\n",
            "Epoch 24, total loss: 0.964, train acc: 0.993, val acc: 0.432 (best 0.432)\n",
            "Epoch 25, total loss: 0.886, train acc: 1.000, val acc: 0.464 (best 0.464)\n",
            "Epoch 26, total loss: 0.807, train acc: 1.000, val acc: 0.484 (best 0.484)\n",
            "Epoch 27, total loss: 0.721, train acc: 1.000, val acc: 0.534 (best 0.534)\n",
            "Epoch 28, total loss: 0.652, train acc: 1.000, val acc: 0.502 (best 0.534)\n",
            "Epoch 29, total loss: 0.578, train acc: 1.000, val acc: 0.524 (best 0.534)\n",
            "Prediction accuracy on the test data is 52.2%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the end after testing different sets of hyperparameters the best resulting set was using a hidden layer of 16 with 2 different convolution layers and a linear layer at the end. The convolutions were done with a mean aggregator. For this dataset simpler and smaller models performed best"
      ],
      "metadata": {
        "id": "BBHazF5oangm"
      }
    }
  ]
}